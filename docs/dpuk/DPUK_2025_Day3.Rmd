---
title: "<b> Introduction to the Linear Model </b>"
subtitle: "DPUK Spring Academy<br><br> "
author: "Josiah King, Umberto Noe, (and credits to Tom Booth)"
institute: "Department of Psychology<br>The University of Edinburgh"
date: "April 2025"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    self_contained: true
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.height = 6)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  #  base_color = "#0F4C81", # DAPR1
  # base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
    base_color = "#95A5A6", #intro
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)

library(tidyverse)
library(kableExtra)
library(car)

theme_set(theme_gray(base_size = 15))
```


# Overview

- Day 1: What is a linear model?
- Day 2: But I have more variables, what now?
- Day 3: Interactions
- Day 4: Is my model any good?



---
class: center, middle
# Day 3
**Interactions (uh-oh)**

---
class: inverse, center, middle

<h2>Part 1: What is an interaction and why are we talking about it? </h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Continuous*binary interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Continuous*Continuous interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 4: Categorical*categorical interactions </h2>

---
#  Lecture notation 

+ For today, we will work with the following equation and notation:

$$y_i = \beta_0 + \beta_1 x_{i} + \beta_2 z_{i} + \beta_3 xz_{i} + \epsilon_i$$

+ $y$ is a continuous outcome

+ $x$ is our first predictor

+ $z$ is our second predictor
	
+ $xz$ is their product or interaction predictors

---
#  General definition of interaction

+ When the effects of one predictor on the outcome differ across levels of another predictor.
  + **Important**: When we have an interaction, we can no longer talk about the overall effect of a variable, holding the others constant.
  + The effects change
  + The effects at specific variables of the interacting variable are called marginal effects.

+ Note interactions are symmetrical. 
  + What does this mean?
    + We can talk about interaction of X with Z, or Z with X.

---
#  General definition 

+ Categorical*continuous interaction:
	+ The slope of the regression line between a continuous predictor and the outcome is different across levels of a categorical predictor.

--

+ Continuous*continuous interaction:
	+ The slope of the regression line between a continuous predictor and the outcome changes as the values of a second continuous predictor change.
	+ May have heard this referred to as moderation.

--

+ Categorical*categorical interaction:
	+ There is a difference in the differences between groups across levels of a second factor.
	+ We will discuss this in the context of linear models for experimental design

---
# Why are we interested in interactions?
+ Often we have theories or ideas which relate to an interaction.

+ For example: 
  + different relationships of mood state to cognitive score dependent on disease status
  + different rates of cognitive decline by disease status. 

+ Questions like these would be tested via inclusion of an interaction term in our model.

---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: What is an interaction and why are we talking about it? </h2>
<h2>Part 2: Continuous*binary interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Continuous*Continuous interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 4: Categorical*categorical interactions </h2>


---
#  Interpretation: Categorical*Continuous 


$$y_i = \beta_0 + \beta_1 x_{i} + \beta_2 z_{i} + \beta_3 xz_{i} + \epsilon_i$$

+ Where $z$ is a binary predictor

  + $\beta_0$ = Value of $y$ when $x$ and $z$ are 0

  + $\beta_1$ = Effect of $x$ (slope) when $z$ = 0 (reference group)

  + $\beta_2$ = Difference intercept between $z$ = 0 and $z$ = 1, when $x$ = 0.

  + $\beta_3$ = Difference in slope across levels of $z$

---
#  Example: Categorical*Continuous 

.pull-left[
+ Suppose I am conducting a study on how years of service within an organisation predicts salary in two different departments, accounts and store managers.

+ y = salary (unit = thousands of pounds)

+ x = years of service

+ z = Department (0=Store managers, 1=Accounts)
]

.pull-right[

```{r, warning=FALSE, message=FALSE, echo=FALSE}
salary1 <- read_csv("./salary_lec.csv")
salary1 <- salary1 %>%
  mutate(
    service = round(service,1),
    salary = round(salary, 3),
    dept = factor(dept, labels = c("StoreManager", "Accounts"))
  )
```


```{r}
salary1 %>%
  slice(1:10)
```

]

---
#  Visualize the data

.pull-left[

```{r eval=FALSE, message=FALSE, warning=FALSE}
salary1 %>%
  ggplot(., aes(x = service, y = salary, 
                colour = dept)) +
  geom_point() +
  xlim(0,8) +
  labs(x = "Years of Service", 
       y = "Salary (£1000)")
```


]

.pull-right[

```{r echo=FALSE}
salary1 %>%
  ggplot(., aes(x = service, y = salary, 
                colour = dept)) +
  geom_point() +
  xlim(0,8) +
  labs(x = "Years of Service", 
       y = "Salary (£1000)")
```

]





---
# Example: Full results

```{r, eval=FALSE}
int <- lm(salary ~ service + dept + service*dept, data = salary1)
summary(int) #<<
```

---
# Example: Full results

```{r, echo=FALSE}
int <- lm(salary ~ service + dept + service*dept, data = salary1)
summary(int) #<<
```


---
#  Example: Categorical*Continuous 

.pull-left[
+ **Intercept** ( $\beta_0$ ): Predicted salary for a store manager (`dept`=0) with 0 years of service is £16,894.

+ **Service** ( $\beta_1$ ): For each additional year of service for a store manager (`dept` = 0), salary increases by £2,736.

+ **Dept** ( $\beta_2$ ): Difference in salary between store managers (`dept` = 0) and accounts (`dept` = 1) with 0 years of service is £4,489.
	
+ **Service:dept** ( $\beta_3$ ): The difference in slope. For each year of service, those in accounts (`dept` = 1) increase by an additional £3,117.

]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
salary1 %>%
  ggplot(., aes(x = service, y = salary, colour = dept)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE)+
  xlim(0,8) +
  labs(x = "Years of Service", y = "Salary (£1000)") 
```
]


---
#  Centering predictors

**Why centre?** 
+ Meaningful interpretation.

  + Interpretation of models with interactions involves evaluation when other variables = 0.
  
  + This makes it quite important that 0 is meaningful in some way.
  	+ Note this is simple with categorical variables.
  	+ We code our reference group as 0 in all dummy variables.
  
  + For continuous variables, we need a meaningful 0 point.

---
#  Example of age 
+ Suppose I have age as a variable in my study with a range of 30 to 85.

+ Age = 0 is not that meaningful.
	+ Essentially means all my parameters are evaluated at point of birth.

+ So what might be meaningful?
	+ Average age? (mean centering)
	+ A fixed point? (e.g. 66 if studying retirement)

---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: What is an interaction and why are we talking about it? </h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Continuous*binary interactions </h2>
<h2>Part 3: Continuous*Continuous interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 4: Categorical*categorical interactions </h2>


---
#  Interpretation: Continuous*Continuous 

$$y_i = \beta_0 + \beta_1 x_{i} + \beta_2 z_{i} + \beta_3 xz_{i} + \epsilon_i$$

+ Lecture notation:
  
  + $\beta_0$ = Value of $y$ when $x$ and $z$ are 0
  
  + $\beta_1$ = Effect of $x$ (slope) when $z$ = 0
  
  + $\beta_2$ = Effect of $z$ (slope) when $x$ = 0
  
  +  $\beta_3$ = Change in slope of $x$ on $y$ across values of $z$ (and vice versa).
	    + Or how the effect of $x$ depends on $z$ (and vice versa)


---
#  Example: Continuous*Continuous 

+ Conducting a study on how years of service and employee performance ratings predicts salary in a sample of managers.

$$y_i = \beta_0 + \beta_1 x_{i} + \beta_2 z_{i} + \beta_3 xz_{i} + \epsilon_i$$

+ $y$ = Salary (unit = thousands of pounds ).

+ $x$ = Years of service.

+ $z$ = Average performance ratings.


---
#  Example: Continuous*Continuous 

```{r echo=FALSE, warning=FALSE, message=FALSE}
salary2 <- read_csv("./salary2.csv")
```

```{r, echo=FALSE}
int2 <- lm(salary ~ serv*perf, data = salary2)
summary(int2)
```

---
#  Example: Continuous*Continuous 

.pull-left[

+ **Intercept**: a manager with 0 years of service and 0 performance rating earns £87,920

+ **Service**: for a manager with 0 performance rating, for each year of service, salary decreases by £10,940
  + slope when performance = 0
  
+ **Performance**: for a manager with 0 years service, for each point of performance rating, salary increases by £3,150.
  + slope when service = 0
  
+ **Interaction**: for every year of service, the relationship between performance and salary increases by £3250.

]


.pull-right[
```{r, echo=FALSE}
test <- summary(int2)
round(test$coefficients,2)
```

]

???
+ What do you notice here?
+ 0 performance and 0 service are odd values
+ lets mean centre both, so 0 = average, and look at this again.


---
# Mean centering

```{r}

salary2 <- salary2 %>%
  mutate(
    perfM = c(scale(perf, scale = F)), #<<
    servM = c(scale(serv, scale = F)) #<<
  )

int3 <- lm(salary ~ servM*perfM, data = salary2)

```


---
# Mean centering

```{r echo=FALSE}
summary(int3)
```

---
#  Example: Continuous*Continuous 

.pull-left[

+ **Intercept**: a manager with average years of service and average performance rating earns £104,850

+ **Service**: a manager with average performance rating, for every year of service, salary increases by £1,420
  + slope when performance = 0 (mean centered)
  
+ **Performance**: a manager with average years service, for each point of performance rating, salary increases by £14,450.
  + slope when service = 0 (mean centered)
  
+ **Interaction**: for every year of service, the relationship between performance and salary increases by £3,250.

]


.pull-right[
```{r, echo=FALSE}
test2 <- summary(int3)
round(test2$coefficients,2)
```

]

---
#  Plotting interactions

+ In our last block we saw we could produce a line for each group of a binary (extends to categorical) variable.

+ These are called simple slopes:
	+ **Regression of the outcome Y on a predictor X at specific values of an interacting variable Z.**

+ For a continuous variable, we could choose any values of Z. 
  + Typically we plot at the mean and +/- 1SD


---
#  `sjPlot`: Simple Slopes 

.pull-left[
```{r, eval = FALSE, warning=FALSE, message=FALSE}
library(sjPlot)
plot_model(int3, type = "int")

```
]

.pull-right[
```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(sjPlot)
plot_model(int3, type = "int")

```

]

---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: What is an interaction and why are we talking about it? </h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Continuous*binary interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Continuous*Continuous interactions </h2>
<h2>Part 4: Categorical*categorical interactions </h2>

---
#  General definition 

+ When the effects of one predictor on the outcome differ across levels of another predictor.

+ Categorical*categorical interaction:
	+ There is a difference in the differences between groups across levels of a second factor.

+ This idea of a difference in differences can be quite tricky to think about.
  + So we will start with some visualization, and then look at two examples.
  
---
# Difference in differences (1)


.pull-left[
```{r,, echo=FALSE}
dat1 <- tibble(
  location = c("London", "London", "Birmingham", "Birmingham"),
  department = c("Accounts","Manager","Accounts","Manager"),
  salary = c(50, 30, 40, 20)
)
```

```{r, echo = FALSE}
eg1 <- matrix(c(50,40,30,20),ncol=2,byrow=TRUE)
colnames(eg1) <- c("London","Birmingham")
rownames(eg1) <- c("Accounts","Manager")
eg1 <- as.table(eg1)
kable(eg1)
```

+ In each plot we look at, think about subtracting the average store managers salary (blue triangle) from the average accounts salary (red circle)

+ In both cases, it is £20,000.

+ Note, the lines are parallel
  + Remember what we have said about parallel lines...no interaction

]

.pull-right[

```{r, echo=FALSE, fig.height=6}
dat1 %>%
  ggplot(., aes(x = location, y = salary, group = department, colour = department, shape = department)) +
  geom_line() +
  geom_point(aes(size = 1.5), show.legend = FALSE) +
  ylim(c(0,60)) +
  geom_segment(aes(x= 0.9 , xend = 0.9 , y=20, yend=40), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  geom_segment(aes(x= 2.1 , xend = 2.1 , y=30, yend=50), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  annotate("text", x = 0.8 , y = 30, label = "20") +
  annotate("text", x = 2.2 , y = 40, label = "20") +
  ggtitle("No difference")

```

]

---
# Difference in differences (2)


.pull-left[
```{r,, echo=FALSE}
dat2 <- tibble(
  location = c("London", "London", "Birmingham", "Birmingham"),
  department = c("Accounts","Manager","Accounts","Manager"),
  salary = c(50, 40, 40, 20)
)
```

```{r, echo = FALSE}
eg2 <- matrix(c(50,40,40,20),ncol=2,byrow=TRUE)
colnames(eg2) <- c("London","Birmingham")
rownames(eg2) <- c("Accounts","Manager")
eg2 <- as.table(eg2)
kable(eg2)
```

+ This time we can see the difference differs.
  + £20,000 in Birmingham
  + £10,000 in London.
  
+ Note the lines are no longer parallel.
  + Suggests interaction.
  + But not crossing (so ordinal interaction)

]

.pull-right[

```{r, echo=FALSE, fig.height=6}
dat2 %>%
  ggplot(., aes(x = location, y = salary, group = department, colour = department, shape = department)) +
  geom_line() +
  geom_point(aes(size = 1.5), show.legend = FALSE) +
  ylim(c(0,60)) +
  geom_segment(aes(x= 0.9 , xend = 0.9 , y=20, yend=40), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  geom_segment(aes(x= 2.1 , xend = 2.1 , y=40, yend=50), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  annotate("text", x = 0.8 , y = 30, label = "20") +
  annotate("text", x = 2.2 , y = 45, label = "10") +
  ggtitle("Difference")

```

]

---
# Difference in differences (3)

.pull-left[
```{r,, echo=FALSE}
dat3 <- tibble(
  location = c("London", "London", "Birmingham", "Birmingham"),
  department = c("Accounts","Manager","Accounts","Manager"),
  salary = c(40, 60, 40, 20)
)
```

```{r, echo = FALSE}
eg3 <- matrix(c(40,60,40,20),ncol=2,byrow=FALSE)
colnames(eg3) <- c("London","Birmingham")
rownames(eg3) <- c("Accounts","Manager")
eg3 <- as.table(eg3)
kable(eg3)
```

+ This time we can see the difference differs.
  + £20,000 in Birmingham
  + -£20,000 in London
  
+ Note the lines are no longer parallel.
  + Suggests interaction.
  + Now crossing (so disordinal interaction)

]

.pull-right[

```{r, echo=FALSE, fig.height=6}
dat3 %>%
  ggplot(., aes(x = location, y = salary, group = department, colour = department, shape = department)) +
  geom_line() +
  geom_point(aes(size = 1.5), show.legend = FALSE) +
  ylim(c(0,60)) +
  geom_segment(aes(x= 0.9 , xend = 0.9 , y=20, yend=40), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  geom_segment(aes(x= 2.1 , xend = 2.1 , y=40, yend=60), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  annotate("text", x = 0.8 , y = 30, label = "20") +
  annotate("text", x = 2.2 , y = 50, label = "-20") +
  ggtitle("Big difference")

```

]

---
#  Interpretation: Categorical*categorical interaction (dummy codes)

$$y_i = \beta_0 + \beta_1 x_{i} + \beta_2 z_{i} + \beta_3 xz_{i} + \epsilon_i$$

+ $\beta_0$ = Value of $y$ when $x$ and $z$ are 0 
  + Expected salary for Accounts in London.
  
+ $\beta_1$ = Difference between levels of $x$ when $z$ = 0 
  + The difference in salary between Accounts in London and Birmingham

+ $\beta_2$ = Difference between levels of $z$ when $x$ = 0.
  + The difference in salary between Accounts and Store managers in London.

+  $\beta_3$ = Difference between levels of $x$ across levels of $z$
  + The difference between salary in Accounts and Store managers between London and Birmingham


---
#  Example: Categorical*categorical
```{r}
int4 <- lm(salary ~ location*department, salary3)
```

```{r, echo=FALSE}
summary(int4)
```

---
#  Example: Categorical*categorical

.pull-left[
```{r, eval=FALSE}
plot_model(int4, type = "int")

```
]

.pull-right[
```{r, echo=FALSE}
plot_model(int4, type = "int")
```

]



---
#  Example: Categorical*categorical
```{r, echo=FALSE}
res <- summary(int4)
round(res$coefficients,3)
```

.pull-left[
+ $\beta_0$ = Value of $y$ when $x$ and $z$ are 0

+ Expected salary for Accounts in London is £50,660.
]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
salary3 %>%
  group_by(location, department) %>%
  summarise(
    Salary = round(mean(salary),3)
  ) %>%
  kable(.)
```
]

---
#  Example: Categorical*categorical
```{r, echo=FALSE}
res <- summary(int4)
round(res$coefficients,3)
```

.pull-left[
+ $\beta_1$ = Difference between levels of $x$ when $z$ = 0

+ The difference in salary between Accounts in London and Birmingham is £1,927. The salary is lower in Birmingham. 

]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
salary3 %>%
  group_by(location, department) %>%
  summarise(
    Salary = round(mean(salary),3)
  ) %>%
  kable(.)
```
]


---
#  Example: Categorical*categorical
```{r, echo=FALSE}
res <- summary(int4)
round(res$coefficients,3)
```

.pull-left[
+ $\beta_2$ = Difference between levels of $z$ when $x$ = 0.

+ The difference in salary between Accounts and Store managers in London is £3,360. The salary is lower for Store Managers. 
]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
salary3 %>%
  group_by(location, department) %>%
  summarise(
    Salary = round(mean(salary),3)
  ) %>%
  kable(.)
```
]

---
#  Example: Categorical*categorical
```{r, echo=FALSE}
res <- summary(int4)
round(res$coefficients,3)
```

.pull-left[
+  $\beta_3$ = Difference between levels of $x$ across levels of $z$

+ The difference between salary for Accounts and Store managers between London and Birmingham, differs by £8,640. The difference is greater in Birmingham than in London.
]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
salary3 %>%
  group_by(location, department) %>%
  summarise(
    Salary = round(mean(salary),3)
  ) %>%
  kable(.)
```
]


---
class: center, middle
# Thanks all!

