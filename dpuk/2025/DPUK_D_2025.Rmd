---
title: "<b> Introduction to the Linear Model </b>"
subtitle: "DPUK Spring Academy<br><br> "
author: "Josiah King, Umberto Noe, (and credits to Tom Booth)"
institute: "Department of Psychology<br>The University of Edinburgh"
date: "April 2025"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    self_contained: true
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.height = 6)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  #  base_color = "#0F4C81", # DAPR1
  # base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
    base_color = "#95A5A6", #intro
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)

library(tidyverse)
library(kableExtra)
library(car)

theme_set(theme_gray(base_size = 15))
```


# Overview

- Day 2: What is a linear model?
- Day 3: But I have more variables, what now?
- Day 4: Interactions
- Day 5: Is my model any good?



---
class: center, middle
# Day 4
**Interactions (uh-oh)**

---
class: inverse, center, middle

<h2>Part 1: What is an interaction and why are we talking about it? </h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Continuous*binary interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Continuous*Continuous interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 4: Categorical*categorical interactions </h2>

---
#  Lecture notation 

+ For today, we will work with the following equation and notation:

$$y_i = \beta_0 + \beta_1 x_{i} + \beta_2 z_{i} + \beta_3 xz_{i} + \epsilon_i$$

+ $y$ is a continuous outcome

+ $x$ is our first predictor

+ $z$ is our second predictor
	
+ $xz$ is their product or interaction predictors

---
#  General definition

+ When the effects of one predictor on the outcome differ across levels of another predictor.

  + **Important**: When we have an interaction, we can no longer talk about the overall effect of a variable, *"holding the others constant"*.
  + The effect changes across values of the interacting variable
  + The effects at specific variables of the interacting variable are called marginal effects (sometimes also "simple effects")

+ Note interactions are symmetrical. 
  + What does this mean?
    + We can talk about interaction of X with Z, or Z with X.

---
#  Interactions with different types of variables

+ Categorical*continuous interaction:

	+ The slope of the regression line between a continuous predictor and the outcome is different across levels of a categorical predictor.

--

+ Continuous*continuous interaction:

	+ The slope of the regression line between a continuous predictor and the outcome changes as the values of a second continuous predictor change.
	+ May have heard this referred to as moderation.

--

+ Categorical*categorical interaction:

	+ There is a difference in the differences between groups across levels of a second factor.

---
# Why are we interested in interactions?  

+ Often we have theories/ideas/questions, which relate to an interaction.

+ For example: 
  + different relationships of mood state to cognitive score dependent on disease status
  + different rates of cognitive decline by disease status. 
  + effect of spending time with partner on relationship satisfaction depends on relationship quality

+ Questions like these would be tested via inclusion of an interaction term in our model.

---
# When should I include an interaction?  

.pull-left[

+ If your research question pre-supposes one

+ If theory suggests it is necessary in order to reflect the underlying data generating process

+ If data visualisations suggest it may be necessary

]

--

.pull-right[

+ An interaction term is another predictor. Additional predictors always explains *some* additional variability.  

+ In the real world, everything interacts with everything else

+ But interactions add complexity and make effects more difficult to interpret because they require the additional context.  

+ Be wary of testing for and including interactions based on significance alone, as you'll risk over-fitting to your specific sample.  

]

---
# How do I include an interaction in R?  


```{r eval=FALSE}
lm( y ~ x + z + x:z, data
```  

shorthand:  
```{r eval=FALSE}
`lm( y ~ x*z, data)`
```

---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: What is an interaction and why are we talking about it? </h2>
<h2>Part 2: Continuous*binary interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Continuous*Continuous interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 4: Categorical*categorical interactions </h2>


---
#  Interpretation: Categorical*Continuous 


$$y_i = \beta_0 + \beta_1 x_{i} + \beta_2 z_{i} + \beta_3 xz_{i} + \epsilon_i$$

+ Where $z$ is a binary predictor

  + $\beta_0$ = Value of $y$ when $x$ and $z$ are 0

  + $\beta_1$ = Effect of $x$ (slope) when $z$ = 0 (reference group)

  + $\beta_2$ = Difference intercept between $z$ = 0 and $z$ = 1, when $x$ = 0.

  + $\beta_3$ = Difference in slope across levels of $z$

---
#  Example: Categorical*Continuous 

.pull-left[
+ Suppose I am conducting a study on how years of service within an organisation predicts salary in two different departments, accounts and store managers.

+ y = salary (unit = thousands of pounds)

+ x = years of service

+ z = Department (0=Store managers, 1=Accounts)
]

.pull-right[

```{r, warning=FALSE, message=FALSE, echo=FALSE}
salary1 <- read_csv("https://uoepsy.github.io/scs/dpuk/data/salary_lec.csv")
salary1 <- salary1 %>%
  mutate(
    service = round(service,1),
    salary = round(salary, 3),
    dept = factor(dept, labels = c("StoreManager", "Accounts"))
  )
```


```{r}
salary1 %>%
  slice(1:10)
```

]

---
#  Visualize the data

.pull-left[

```{r eval=FALSE, message=FALSE, warning=FALSE}
salary1 %>%
  ggplot(., aes(x = service, y = salary, 
                colour = dept)) +
  geom_point() +
  xlim(0,8) +
  labs(x = "Years of Service", 
       y = "Salary (1000gbp)")
```


]

.pull-right[

```{r echo=FALSE}
salary1 %>%
  ggplot(., aes(x = service, y = salary, 
                colour = dept)) +
  geom_point() +
  xlim(0,8) +
  labs(x = "Years of Service", 
       y = "Salary (1000gbp)")
```

]





---
#  Example: Categorical*Continuous 

```{r}
int <- lm(salary ~ service + dept + service*dept, data = salary1)
summary(int)
```


---
#  Interpretation: Categorical*Continuous 

.pull-left[
+ **Intercept** ( $\beta_0$ ): Predicted salary for a store manager (`dept`=0) with 0 years of service is £16,894.

+ **Service** ( $\beta_1$ ): For each additional year of service for a store manager (`dept` = 0), salary increases by £2,736.

+ **Dept** ( $\beta_2$ ): Difference in salary between store managers (`dept` = 0) and accounts (`dept` = 1) with 0 years of service is £4,489.
	
+ **Service:dept** ( $\beta_3$ ): The difference in slope. For each year of service, those in accounts (`dept` = 1) increase by an additional £3,117.

]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
salary1 %>%
  ggplot(., aes(x = service, y = salary, colour = dept)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE)+
  geom_smooth(method="lm",se=F,fullrange=T,lty="dashed")+
  xlim(0,8) +
  labs(x = "Years of Service", y = "Salary (1000gbp)") 
```
]


---
#  Centering predictors

**Why centre?** 
+ Meaningful interpretation.

  + Interpretation of models with interactions involves evaluation when other variables = 0.
  
  + This makes it quite important that 0 is meaningful in some way.
  	+ Note this is simple with categorical variables.
  	+ We code our reference group as 0 in all dummy variables.
  
  + For continuous variables, we need a meaningful 0 point.

---
#  Example of age 
+ Suppose I have age as a variable in my study with a range of 30 to 85.

+ Age = 0 is not that meaningful.
	+ Essentially means all my parameters are evaluated at point of birth.

+ So what might be meaningful?
	+ Average age? (mean centering)
	+ A fixed point? (e.g. 66 if studying retirement)

---
#  Initial model

.pull-left[

```{r eval=FALSE}
int <- lm(salary ~ service + dept + service:dept, data = salary1)
summary(int)
```
```
Coefficients:
                     Estimate Std. Error t value
(Intercept)           16.8937     4.4638   3.785
service                2.7364     0.9166   2.986
deptAccounts           4.4887     6.3111   0.711
service:deptAccounts   3.1174     1.2698   2.455
```

]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
m1 = lm(salary~dept*service,salary1)
m2 = lm(salary~dept*scale(service),salary1)

salary1 %>%
  ggplot(., aes(x = service, y = salary, colour = dept)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE)+
    geom_smooth(method="lm",se=F,fullrange=T,lty="dashed")+
    geom_point(x=0,y=coef(m1)[1], size=5)+
    geom_point(x=0,y=sum(coef(m1)[1:2]), size=5,aes(col="Accounts"))+
  xlim(-.1,8) +
  labs(x = "Years of Service", y = "Salary (1000gbp)") 
```
]

---
#  Mean-centered

.pull-left[

```{r eval=FALSE}
salary1 <- salary1 |>
    mutate(
        service_m = service - mean(service)
    )
int_a <- lm(salary ~ service_m + dept + service_m:dept, data = salary1)
summary(int_a)
```
```
Coefficients:
                       Estimate Std. Error t value
(Intercept)             30.1982     0.9081  33.256
service_m                2.7364     0.9166   2.986
deptAccounts            19.6455     1.3106  14.989
service_m:deptAccounts   3.1174     1.2698   2.455
```

]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
m1 = lm(salary~dept*service,salary1)
m2 = lm(salary~dept*scale(service),salary1)

salary1 %>%
  ggplot(., aes(x = service, y = salary, colour = dept)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE)+
    geom_smooth(method="lm",se=F,fullrange=T,lty="dashed")+
    geom_point(x=mean(salary1$service),y=coef(m2)[1], size=5)+
    geom_point(x=mean(salary1$service),y=sum(coef(m2)[1:2]), size=5,aes(col="Accounts"))+
  xlim(-.1,8) +
  labs(x = "Years of Service", y = "Salary (1000gbp)") 
```
]

---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: What is an interaction and why are we talking about it? </h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Continuous*binary interactions </h2>
<h2>Part 3: Continuous*Continuous interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 4: Categorical*categorical interactions </h2>


---
#  Interpretation: Continuous*Continuous 

$$y_i = \beta_0 + \beta_1 x_{i} + \beta_2 z_{i} + \beta_3 xz_{i} + \epsilon_i$$

+ Lecture notation:
  
  + $\beta_0$ = Value of $y$ when $x$ and $z$ are 0
  
  + $\beta_1$ = Effect of $x$ (slope) when $z$ = 0
  
  + $\beta_2$ = Effect of $z$ (slope) when $x$ = 0
  
  +  $\beta_3$ = Change in slope of $x$ on $y$ across values of $z$ (and vice versa).
	    + Or how the effect of $x$ depends on $z$ (and vice versa)


---
#  Example: Continuous*Continuous 

+ Conducting a study on how years of service and employee performance ratings predicts salary in a sample of managers.

$$y_i = \beta_0 + \beta_1 x_{i} + \beta_2 z_{i} + \beta_3 xz_{i} + \epsilon_i$$

+ $y$ = Salary (unit = thousands of pounds ).

+ $x$ = Years of service.

+ $z$ = Average performance ratings.


---
#  Example: Continuous*Continuous 

```{r echo=FALSE, warning=FALSE, message=FALSE}
salary2 <- read_csv("https://uoepsy.github.io/scs/dpuk/data/salary2.csv")
```

```{r, echo=FALSE}
int2 <- lm(salary ~ serv*perf, data = salary2)
summary(int2)
```

---
#  Example: Continuous*Continuous 

.pull-left[

+ **Intercept**: a manager with 0 years of service and 0 performance rating earns £87,920

+ **Service**: for a manager with 0 performance rating, for each year of service, salary decreases by £10,940
  + slope when performance = 0
  
+ **Performance**: for a manager with 0 years service, for each point of performance rating, salary increases by £3,150.
  + slope when service = 0
  
+ **Interaction**: for every year of service, the relationship between performance and salary increases by £3250.

]


.pull-right[
```{r, echo=FALSE}
test <- summary(int2)
round(test$coefficients,2)
```

]

???
+ What do you notice here?
+ 0 performance and 0 service are odd values
+ lets mean centre both, so 0 = average, and look at this again.


---
# Mean centering

```{r}

salary2 <- salary2 %>%
  mutate(
    perfM = c(scale(perf, scale = F)), #<<
    servM = c(scale(serv, scale = F)) #<<
  )

int3 <- lm(salary ~ servM*perfM, data = salary2)

```


---
# Mean centering

```{r echo=FALSE}
summary(int3)
```

---
#  Example: Continuous*Continuous 

.pull-left[

+ **Intercept**: a manager with average years of service and average performance rating earns £104,850

+ **Service**: a manager with average performance rating, for every year of service, salary increases by £1,420
  + slope when performance = 0 (mean centered)
  
+ **Performance**: a manager with average years service, for each point of performance rating, salary increases by £14,450.
  + slope when service = 0 (mean centered)
  
+ **Interaction**: for every year of service, the relationship between performance and salary increases by £3,250.

]


.pull-right[
```{r, echo=FALSE}
test2 <- summary(int3)
round(test2$coefficients,2)
```

]

---
#  Plotting interactions

+ In our last block we saw we could produce a line for each group of a binary (extends to categorical) variable.

+ These are called simple slopes:
	+ **Regression of the outcome Y on a predictor X at specific values of an interacting variable Z.**

+ For a continuous variable, we could choose any values of Z. 
  + Typically we plot at the mean and +/- 1SD


---
#  `sjPlot`: Simple Slopes 

.pull-left[
```{r, eval = FALSE, warning=FALSE, message=FALSE}
library(sjPlot)
plot_model(int3, type = "int")
```
]

.pull-right[
```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(sjPlot)
plot_model(int3, type = "int")
```

]

---
#  `sjPlot`: Simple Slopes 

.pull-left[
```{r, eval = FALSE, warning=FALSE, message=FALSE}
library(sjPlot)
plot_model(int3, type = "pred",
           terms = c("servM","perfM [-2,0,2]"))
```
]

.pull-right[
```{r, echo = FALSE, warning=FALSE, message=FALSE}
plot_model(int3, type = "pred",
           terms = c("servM","perfM [-2,0,2]"))
```

]

---
#  `sjPlot`: Simple Slopes 

.pull-left[
```{r, eval = FALSE, warning=FALSE, message=FALSE}
library(sjPlot)
plot_model(int3, type = "pred",
           terms = c("servM","perfM [-2,-1,0,1,2]"))
```
]

.pull-right[
```{r, echo = FALSE, warning=FALSE, message=FALSE}
plot_model(int3, type = "pred",
           terms = c("servM","perfM [-2,-1,0,1,2]"))
```

]

---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: What is an interaction and why are we talking about it? </h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Continuous*binary interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Continuous*Continuous interactions </h2>
<h2>Part 4: Categorical*categorical interactions </h2>

---
#  General definition 

+ When the effects of one predictor on the outcome differ across levels of another predictor.

+ Categorical*categorical interaction:
	+ There is a difference in the differences between groups across levels of a second factor.

+ This idea of a difference in differences can be quite tricky to think about.
  + So we will start with some visualization, and then look at two examples.
  
---
# Difference in differences (1)


.pull-left[
```{r,, echo=FALSE}
dat1 <- tibble(
  location = c("London", "London", "Birmingham", "Birmingham"),
  department = c("Accounts","Manager","Accounts","Manager"),
  salary = c(50, 30, 40, 20)
)
```

```{r, echo = FALSE}
eg1 <- matrix(c(50,40,30,20),ncol=2,byrow=TRUE)
colnames(eg1) <- c("London","Birmingham")
rownames(eg1) <- c("Accounts","Manager")
eg1 <- as.table(eg1)
kable(eg1)
```

+ In each plot we look at, think about subtracting the average store managers salary (blue triangle) from the average accounts salary (red circle)

+ In both cases, it is £20,000.

+ Note, the lines are parallel
  + Remember what we have said about parallel lines...no interaction

]

.pull-right[

```{r, echo=FALSE, fig.height=6}
dat1 %>%
  ggplot(., aes(x = location, y = salary, group = department, colour = department, shape = department)) +
  geom_line() +
  geom_point(aes(size = 1.5), show.legend = FALSE) +
  ylim(c(0,60)) +
  geom_segment(aes(x= 0.9 , xend = 0.9 , y=20, yend=40), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  geom_segment(aes(x= 2.1 , xend = 2.1 , y=30, yend=50), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  annotate("text", x = 0.8 , y = 30, label = "20") +
  annotate("text", x = 2.2 , y = 40, label = "20") +
  ggtitle("No difference")

```

]

---
# Difference in differences (2)


.pull-left[
```{r,, echo=FALSE}
dat2 <- tibble(
  location = c("London", "London", "Birmingham", "Birmingham"),
  department = c("Accounts","Manager","Accounts","Manager"),
  salary = c(50, 40, 40, 20)
)
```

```{r, echo = FALSE}
eg2 <- matrix(c(50,40,40,20),ncol=2,byrow=TRUE)
colnames(eg2) <- c("London","Birmingham")
rownames(eg2) <- c("Accounts","Manager")
eg2 <- as.table(eg2)
kable(eg2)
```

+ This time we can see the difference differs.
  + £20,000 in Birmingham
  + £10,000 in London.
  
+ Note the lines are no longer parallel.
  + Suggests interaction.
  + But not crossing (so ordinal interaction)

]

.pull-right[

```{r, echo=FALSE, fig.height=6}
dat2 %>%
  ggplot(., aes(x = location, y = salary, group = department, colour = department, shape = department)) +
  geom_line() +
  geom_point(aes(size = 1.5), show.legend = FALSE) +
  ylim(c(0,60)) +
  geom_segment(aes(x= 0.9 , xend = 0.9 , y=20, yend=40), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  geom_segment(aes(x= 2.1 , xend = 2.1 , y=40, yend=50), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  annotate("text", x = 0.8 , y = 30, label = "20") +
  annotate("text", x = 2.2 , y = 45, label = "10") +
  ggtitle("Difference")

```

]

---
# Difference in differences (3)

.pull-left[
```{r,, echo=FALSE}
dat3 <- tibble(
  location = c("London", "London", "Birmingham", "Birmingham"),
  department = c("Accounts","Manager","Accounts","Manager"),
  salary = c(40, 60, 40, 20)
)
```

```{r, echo = FALSE}
eg3 <- matrix(c(40,60,40,20),ncol=2,byrow=FALSE)
colnames(eg3) <- c("London","Birmingham")
rownames(eg3) <- c("Accounts","Manager")
eg3 <- as.table(eg3)
kable(eg3)
```

+ This time we can see the difference differs.
  + £20,000 in Birmingham
  + -£20,000 in London
  
+ Note the lines are no longer parallel.
  + Suggests interaction.
  + Now crossing (so disordinal interaction)

]

.pull-right[

```{r, echo=FALSE, fig.height=6}
dat3 %>%
  ggplot(., aes(x = location, y = salary, group = department, colour = department, shape = department)) +
  geom_line() +
  geom_point(aes(size = 1.5), show.legend = FALSE) +
  ylim(c(0,60)) +
  geom_segment(aes(x= 0.9 , xend = 0.9 , y=20, yend=40), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  geom_segment(aes(x= 2.1 , xend = 2.1 , y=40, yend=60), 
               arrow=arrow(type = "closed", end = "both", length = unit(0.2, "cm")), 
               colour = "black", linetype = "dashed") +
  annotate("text", x = 0.8 , y = 30, label = "20") +
  annotate("text", x = 2.2 , y = 50, label = "-20") +
  ggtitle("Big difference")

```

]

---
#  Interpretation: Categorical*categorical interaction (dummy codes)

$$y_i = \beta_0 + \beta_1 x_{i} + \beta_2 z_{i} + \beta_3 xz_{i} + \epsilon_i$$

+ $\beta_0$ = Value of $y$ when $x$ and $z$ are 0 
  + Expected salary for Accounts in London.
  
+ $\beta_1$ = Difference between levels of $x$ when $z$ = 0 
  + The difference in salary between Accounts in London and Birmingham

+ $\beta_2$ = Difference between levels of $z$ when $x$ = 0.
  + The difference in salary between Accounts and Store managers in London.

+  $\beta_3$ = Difference between levels of $x$ across levels of $z$
  + The difference between salary in Accounts and Store managers between London and Birmingham


---
#  Example: Categorical*categorical

```{r}
#| eval: false
#| include: false
library(tidyverse)
set.seed(47821)
salary3 <- expand_grid(
    location = 0:1,
    department = 0:1,
    n = 1:25
) |>
    mutate(
        salary = 50.66 - 1.9276*location -3.36*department -8.64*location*department + rnorm(n(),0,5.059),
        location = factor(ifelse(location==0,"London","Birmingham"),levels=c("London","Birmingham")),
        department = ifelse(department==0,"Accounts","Manager")
    )
write_csv(salary3,file="data/salary3.csv")
```


```{r message=FALSE}
salary3 <- read_csv("https://uoepsy.github.io/scs/dpuk/data/salary3.csv") 
salary3 <- 
    salary3 |> mutate(
        location = factor(location, levels = c("London","Birmingham")),
        department = factor(department)
)

int4 <- lm(salary ~ location*department, salary3)

```

---
#  Example: Categorical*categorical

```{r, echo=FALSE}
summary(int4)
```

---
#  Example: Categorical*categorical

.pull-left[
```{r, eval=FALSE}
plot_model(int4, type = "int")
```
]

.pull-right[
```{r, echo=FALSE, message=FALSE}
plot_model(int4, type = "int")
```

]



---
#  Example: Categorical*categorical
```{r, echo=FALSE}
res <- summary(int4)
round(res$coefficients,3)
```

.pull-left[
+ $\beta_0$ = Value of $y$ when $x$ and $z$ are 0

+ Expected salary for Accounts in London is £50,481.
]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
salary3 %>%
  group_by(location, department) %>%
  summarise(
    Salary = round(mean(salary),3)
  ) %>%
  kable(.)
```
]

---
#  Example: Categorical*categorical
```{r, echo=FALSE}
res <- summary(int4)
round(res$coefficients,3)
```

.pull-left[
+ $\beta_1$ = Difference between levels of $x$ when $z$ = 0

+ The difference in salary between Accounts in London and Birmingham is £1,895. The salary is lower in Birmingham. 

]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
salary3 %>%
  group_by(location, department) %>%
  summarise(
    Salary = round(mean(salary),3)
  ) %>%
  kable(.)
```
]


---
#  Example: Categorical*categorical
```{r, echo=FALSE}
res <- summary(int4)
round(res$coefficients,3)
```

.pull-left[
+ $\beta_2$ = Difference between levels of $z$ when $x$ = 0.

+ The difference in salary between Accounts and Store managers in London is £3,956. The salary is lower for Store Managers. 
]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
salary3 %>%
  group_by(location, department) %>%
  summarise(
    Salary = round(mean(salary),3)
  ) %>%
  kable(.)
```
]

---
#  Example: Categorical*categorical
```{r, echo=FALSE}
res <- summary(int4)
round(res$coefficients,3)
```

.pull-left[
+  $\beta_3$ = Difference between levels of $x$ across levels of $z$

+ The difference between salary for Accounts and Store managers between London and Birmingham, differs by £9,601. The difference is greater in Birmingham than in London.
]


.pull-right[
```{r, echo=FALSE, warning=FALSE, message=FALSE}
salary3 %>%
  group_by(location, department) %>%
  summarise(
    Salary = round(mean(salary),3)
  ) %>%
  kable(.)
```
]

---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: What is an interaction and why are we talking about it? </h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Continuous*binary interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Continuous*Continuous interactions </h2>
<h2 style="text-align: left;opacity:0.3;">Part 4: Categorical*categorical interactions </h2>
<h2>Pulling it together</h2>

---
# Non-parallel

.pull-left[
```{r echo=FALSE,message=FALSE}
#| out-height: "350px"
mwdata2<-read_csv("https://uoepsy.github.io/data/wellbeing_rural.csv") %>% mutate(
  isRural = factor(ifelse(location=="rural","rural","notrural"))
)
df <- mwdata2 |> transmute(
  y = wellbeing,
  x1 = outdoor_time,
  x2 = ifelse(isRural=="rural","Level2","Level1")
)


fit<-lm(wellbeing~outdoor_time+isRural, data=mwdata2)
with(mwdata2, plot(wellbeing ~ outdoor_time, col=isRural, xlab="x1",ylab="y",main="y~x1+x2\n(x2 is categorical)"))
abline(a = coef(fit)[1],b=coef(fit)[2])
abline(a = coef(fit)[1]+coef(fit)[3],b=coef(fit)[2], col="red")
```
]
.pull-right[
```{r echo=FALSE,message=FALSE}
#| out-height: "350px"
fit<-lm(wellbeing~outdoor_time*isRural, data=mwdata2)
with(mwdata2, plot(wellbeing ~ outdoor_time, col=isRural, xlab="x1",ylab="y",main="y~x1+x2+x1:x2\n(x2 is categorical)"))
abline(a = coef(fit)[1],b=coef(fit)[2])
abline(a = coef(fit)[1]+coef(fit)[3],b=coef(fit)[2]+coef(fit)[4], col="red")
```
]

---
# Non-parallel

.pull-left[
```{r echo=FALSE,message=FALSE}
#| out-height: "350px"
set.seed(913)
df <- tibble(
  x1 = round(pmax(0,rnorm(50,4,2)),1),
  x2 = round(pmax(0,rnorm(50,4,2)),1),
  y = 8 + .6*x1 + .5*x2 + .8*x1*x2 + rnorm(50,0,4),
  yb = rbinom(50,1,plogis(scale(y)))
)

modl2 <- lm(y~x1+x2,df)

x1_pred <- df |> with(seq(min(x1),max(x1),length.out=20))
x2_pred <- df |> with(seq(min(x2),max(x2),length.out=20))

ac <- expand.grid(x1=x1_pred,x2=x2_pred) 

ypred <- matrix(predict(modl2,type="response",
                             newdata=ac),nrow=20)

library(plot3D)

persp3D(x=x1_pred,y=x2_pred,z=ypred,theta=45,phi=15,
        type="surface",xlab="x1",ylab="x2",zlab="y",
        xlim=c(0,9), ylim=c(0,8),
        zlim=c(min(df$y),max(df$y)+2),border="black",
      #col="white",
        colkey=FALSE,
        main="y~x1+x2")
points3D(x=df$x1,y=df$x2,z=df$y,col="black",pch=16,add=TRUE)
```
]

.pull-right[
```{r echo=FALSE,message=FALSE}
#| out-height: "350px"
modl2 <- lm(y~x1*x2,df)

x1_pred <- df |> with(seq(min(x1),max(x1),length.out=20))
x2_pred <- df |> with(seq(min(x2),max(x2),length.out=20))

ac <- expand.grid(x1=x1_pred,x2=x2_pred) 

ypred <- matrix(predict(modl2,type="response",
                             newdata=ac),nrow=20)

persp3D(x=x1_pred,y=x2_pred,z=ypred,theta=45,phi=15,
        type="surface",xlab="x1",ylab="x2",zlab="y",
        xlim=c(0,9), ylim=c(0,8),
        zlim=c(min(df$y),max(df$y)+2),
        #col="white",
        border="black",
        colkey=FALSE,
        main="y~x1+x2+x1:x2")
points3D(x=df$x1,y=df$x2,z=df$y,col="black",pch=16,add=TRUE)
```

]

---
# coefficients in the presence of an interaction

**Y ~ A + B + A:B**

```
Coefficients:
                         Estimate 
(Intercept)               - when A and B are zero
A                         - slope of A when B is zero
B                         - slope of B when A is zero
A:B                       -
```

---
# the interaction term is an adjustment

**Y ~ A + B + A:B**

```
Coefficients:
                         Estimate 
(Intercept)               - when A and B are zero
A                         - slope of A when B is zero
B                         - slope of B when A is zero
A:B                       - how the slope of A changes when B increases by 1
```

---
# the interaction term is an adjustment

**Y ~ A + B + A:B**

```
Coefficients:
                         Estimate 
(Intercept)               - when A and B are zero
A                         - slope of A when B is zero
B                         - slope of B when A is zero
A:B                       - how the slope of B changes when A increases by 1
```

---
# coefficients in the presence of an interaction

**Y ~ A + B + A:B + C**

```
Coefficients:
                         Estimate 
(Intercept)               - when A, B and C are zero
A                         - slope of A when B is zero, holding C constant
B                         - slope of B when A is zero, holding C constant
C                         - slope of C, holding A and B constant
A:B                       - how the slope of B changes when A increases by 1, holding C constant
```



---
class: center, middle
# Thanks all!

